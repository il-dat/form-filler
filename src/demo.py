#!/usr/bin/env python3
"""
CrewAI Demo script for Vietnamese Document Form Filler.

Shows CrewAI-powered multi-agent capabilities.
"""

import asyncio
import json
import os
import tempfile
import time
from pathlib import Path

from batch_processor import BatchProcessor
from document_processor import DocumentProcessor

from form_filler.batch_processor import CrewAIBatchProcessor
from form_filler.crew.document_processing_crew import DocumentProcessingCrew

# Demo data - sample Vietnamese text
SAMPLE_VIETNAMESE_TEXT = """
H·ªç v√† t√™n: Nguy·ªÖn VƒÉn An
Ng√†y sinh: 15/03/1990
ƒê·ªãa ch·ªâ: 123 Ph·ªë Hu·∫ø, Qu·∫≠n Hai B√† Tr∆∞ng, H√† N·ªôi
S·ªë ƒëi·ªán tho·∫°i: 0123456789
Email: nguyen.van.an@email.com
Tr√¨nh ƒë·ªô h·ªçc v·∫•n: C·ª≠ nh√¢n C√¥ng ngh·ªá Th√¥ng tin

Kinh nghi·ªám l√†m vi·ªác:
- 2015-2018: L·∫≠p tr√¨nh vi√™n t·∫°i C√¥ng ty ABC
- 2018-2022: Tr∆∞·ªüng nh√≥m ph√°t tri·ªÉn t·∫°i C√¥ng ty XYZ
- 2022-hi·ªán t·∫°i: Ki·∫øn tr√∫c s∆∞ ph·∫ßn m·ªÅm t·∫°i C√¥ng ty DEF

K·ªπ nƒÉng:
- Ng√¥n ng·ªØ l·∫≠p tr√¨nh: Python, Java, JavaScript
- Framework: Django, React, Spring Boot
- C∆° s·ªü d·ªØ li·ªáu: MySQL, PostgreSQL, MongoDB
- DevOps: Docker, Kubernetes, AWS
"""

SAMPLE_FORM_CONTENT = """
EMPLOYMENT APPLICATION FORM

Personal Information:
Name: ___________________
Date of Birth: ___________________
Address: ___________________________________
Phone Number: ___________________
Email: ___________________

Education:
Highest Degree: ___________________
Institution: ___________________

Work Experience:
Previous Position: ___________________
Company: ___________________
Years of Experience: ___________________

Skills:
Technical Skills: ___________________________________
Programming Languages: ___________________
Frameworks: ___________________
Databases: ___________________

Additional Information:
___________________________________________
___________________________________________
"""


def demo_crewai_single_document():
    """Demonstrate CrewAI single document processing."""
    print("ü§ñ Demo 1: CrewAI Single Document Processing")
    print("-" * 50)

    # Create temporary files
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as source_file:
        source_file.write(SAMPLE_VIETNAMESE_TEXT)
        source_path = source_file.name

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as form_file:
        form_file.write(SAMPLE_FORM_CONTENT)
        form_path = form_file.name

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as output_file:
        output_path = output_file.name

    # Initialize CrewAI processor
    print("ü§ñ Initializing CrewAI crew...")
    crew_processor = DocumentProcessingCrew(
        text_model="llama3.2:3b", extraction_method="traditional", vision_model="llava:7b"
    )

    print("üìÑ Processing Vietnamese CV with CrewAI agents...")
    print(f"Source: {Path(source_path).name}")
    print(f"Form: {Path(form_path).name}")
    print("\nü§ñ CrewAI Agents in Action:")
    print("  1. üìÑ Document Collector Agent - Extracting text...")
    print("  2. üîÑ Translator Agent - Translating Vietnamese to English...")
    print("  3. üîç Form Analyst Agent - Analyzing form structure...")
    print("  4. ‚úçÔ∏è Form Filler Agent - Filling form intelligently...")

    # Process document
    result = crew_processor.process_document(source_path, form_path, output_path)

    if result.success:
        print("\n‚úÖ CrewAI Success!")
        print(f"Output saved to: {output_path}")

        # Show agent collaboration results
        if Path(output_path).exists():
            with open(output_path) as f:
                content = f.read()
                print("\nüìã CrewAI Filled Form Preview:")
                print(content[:300] + "..." if len(content) > 300 else content)

        print(f"ü§ñ Agent Configuration: {result.metadata.get('extraction_method')} extraction")
        print(f"üì± Text Model: {result.metadata.get('text_model')}")
        if result.metadata.get("vision_model"):
            print(f"üëÅÔ∏è Vision Model: {result.metadata.get('vision_model')}")
    else:
        print(f"‚ùå CrewAI Failed: {result.error}")

    # Cleanup
    Path(source_path).unlink()
    Path(form_path).unlink()
    if Path(output_path).exists():
        Path(output_path).unlink()

    print("\n")


def demo_crewai_agent_capabilities():
    """Demonstrate individual CrewAI agent capabilities."""
    print("ü§ñ Demo 2: CrewAI Agent Capabilities")
    print("-" * 50)

    from document_processor import (
        DocumentExtractionTool,
        FormAnalysisTool,
        FormFillingTool,
        TranslationTool,
    )

    # Create temp files
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as temp_file:
        temp_file.write(SAMPLE_VIETNAMESE_TEXT)
        temp_path = temp_file.name

    print("üîß CrewAI Tool 1: DocumentExtractionTool")
    extractor = DocumentExtractionTool(extraction_method="traditional")
    extracted_text = extractor._run(temp_path)
    print(f"‚úÖ Extracted {len(extracted_text)} characters")
    print(f"üìù Sample: {extracted_text[:100]}...")

    print("\nüîß CrewAI Tool 2: TranslationTool")
    translator = TranslationTool(model="llama3.2:3b")
    english_text = translator._run(extracted_text)
    print("‚úÖ Translation completed by CrewAI agent")
    print(f"üìù Sample: {english_text[:100]}...")

    print("\nüîß CrewAI Tool 3: FormAnalysisTool")
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as form_file:
        form_file.write(SAMPLE_FORM_CONTENT)
        form_path = form_file.name

    form_analyzer = FormAnalysisTool()
    form_analyzer._run(form_path)
    print("‚úÖ Form analysis completed")
    print("üìù Found form fields in structure")

    print("\nüîß CrewAI Tool 4: FormFillingTool")
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as output_file:
        output_path = output_file.name
    form_filler = FormFillingTool(model="llama3.2:3b")
    filling_result = form_filler._run(form_path, english_text, output_path)
    print("‚úÖ Form filling completed by CrewAI agent")
    print(f"üìù Result: {filling_result}")

    # Cleanup
    Path(temp_path).unlink()
    Path(form_path).unlink()
    if Path(output_path).exists():
        Path(output_path).unlink()

    print("\n")


def demo_crewai_batch_processing():
    """Demonstrate CrewAI batch processing."""
    print("ü§ñ Demo 3: CrewAI Batch Processing")
    print("-" * 50)

    # Create sample documents
    sample_documents = [
        f"T√†i li·ªáu {i}: T√™n: Ng∆∞·ªùi {i}, Tu·ªïi: {20+i}, ƒê·ªãa ch·ªâ: H√† N·ªôi, Vi·ªát Nam"
        for i in range(1, 4)
    ]

    # Create temporary directory structure
    temp_dir = Path(tempfile.mkdtemp())
    input_dir = temp_dir / "input"
    output_dir = temp_dir / "output"
    input_dir.mkdir()
    output_dir.mkdir()

    # Create sample files
    form_path = temp_dir / "form.txt"
    with open(form_path, "w") as f:
        f.write(SAMPLE_FORM_CONTENT)

    # Create input documents
    for i, content in enumerate(sample_documents, 1):
        doc_path = input_dir / f"document_{i}.txt"
        with open(doc_path, "w") as f:
            f.write(content)

    print(f"üìÅ Created {len(sample_documents)} sample documents")
    print(f"Input directory: {input_dir}")
    print(f"Output directory: {output_dir}")

    # Initialize CrewAI batch processor
    print("\nü§ñ Initializing CrewAI Batch Processor...")
    batch_processor = CrewAIBatchProcessor(
        text_model="llama3.2:3b",
        extraction_method="traditional",
        vision_model="llava:7b",
        max_concurrent=2,
        timeout=60,
    )

    # Discover jobs
    job_count = batch_processor.discover_jobs(
        str(input_dir), str(form_path), str(output_dir), "*.txt"
    )

    print(f"üîç Discovered {job_count} processing jobs")
    print("ü§ñ CrewAI Configuration:")
    print("  - Max concurrent crews: 2")
    print("  - Each crew has 4 specialized agents")
    print(f"  - Total agents working: {job_count * 4} (across all crews)")

    # Progress callback
    def progress_callback(completed, total, job):
        progress = (completed / total) * 100
        status = "‚úÖ" if job.status == "completed" else "‚ùå"
        print(
            f"Progress: {completed}/{total} ({progress:.1f}%) - {status} {job.source_path.name} (Crew: {job.crew_id})"
        )

    # Process batch
    print("\nüöÄ Starting CrewAI batch processing...")
    print("Multiple crews working in parallel...")
    stats = batch_processor.process_all(progress_callback)

    print("\nüìä CrewAI Batch Processing Results:")
    print(f"Total: {stats['total']}")
    print(f"Completed: {stats['completed']}")
    print(f"Failed: {stats['failed']}")
    print(f"Success Rate: {stats['success_rate']:.1f}%")
    print(f"Total Time: {stats['total_time']:.2f}s")
    print(f"Average per Job: {stats['average_job_time']:.2f}s")
    print(f"Extraction Method: {stats['extraction_method']}")
    print(f"Text Model: {stats['text_model']}")

    # Cleanup
    import shutil

    shutil.rmtree(temp_dir)

    print("\n")


def demo_crewai_extraction_methods():
    """Compare CrewAI extraction methods (Traditional, AI, OpenAI)."""
    print("ü§ñ Demo 4: CrewAI Extraction Methods Comparison")
    print("-" * 50)

    # Create sample document
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as temp_file:
        temp_file.write(SAMPLE_VIETNAMESE_TEXT)
        temp_path = temp_file.name

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as form_file:
        form_file.write(SAMPLE_FORM_CONTENT)
        form_path = form_file.name

    # Test Traditional Method
    print("üîß Testing Traditional Extraction with CrewAI...")
    traditional_crew = DocumentProcessingCrew(
        text_model="llama3.2:3b", extraction_method="traditional", vision_model="llava:7b"
    )

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as output_file:
        output_traditional = output_file.name

    start_time = time.time()
    result_traditional = traditional_crew.process_document(
        temp_path, form_path, output_traditional
    )
    traditional_time = time.time() - start_time

    print(f"‚úÖ Traditional method: {traditional_time:.2f}s")
    print(f"   Status: {'Success' if result_traditional.success else 'Failed'}")

    # Test AI Method (simulated - would require vision model)
    print("\nüß† Testing AI Extraction with CrewAI...")
    # Simulate AI configuration without actually running it since it requires vision model
    DocumentProcessingCrew(
        text_model="llama3.2:3b", extraction_method="ai", vision_model="llava:7b"
    )

    # Note: This would require actual vision model installation
    print("   ‚ö†Ô∏è AI extraction requires vision model (llava:7b)")
    print("   Demo shows configuration and workflow")

    print("‚öôÔ∏è AI method configuration ready")
    print("   Agents: DocumentCollector (AI) ‚Üí Translator ‚Üí FormAnalyst ‚Üí FormFiller")
    print("   Vision Model: llava:7b (if available)")

    # Test OpenAI Method (requires API key)
    print("\n‚òÅÔ∏è Testing OpenAI Extraction with CrewAI...")
    openai_api_key = os.environ.get("OPENAI_API_KEY")

    if openai_api_key:
        # Create OpenAI-based crew
        DocumentProcessingCrew(
            text_model="llama3.2:3b",
            extraction_method="openai",
            vision_model="llava:7b",
            openai_api_key=openai_api_key,
            openai_model="gpt-4-vision-preview",
        )

        print("   ‚ÑπÔ∏è Using OpenAI API for extraction")
        print("   Demo shows configuration and workflow")
        print("‚öôÔ∏è OpenAI method configuration ready")
        print("   Agents: DocumentCollector (OpenAI) ‚Üí Translator ‚Üí FormAnalyst ‚Üí FormFiller")
        print("   OpenAI Model: gpt-4-vision-preview")
    else:
        print("   ‚ö†Ô∏è OpenAI extraction requires API key")
        print("   To test, set OPENAI_API_KEY environment variable")

    # Comparison of all methods
    print("\nüìä CrewAI Extraction Method Comparison:")
    print("Traditional: Fast, reliable for clean text documents")
    print("AI: Better for complex layouts, handwriting using local models")
    print("OpenAI: Highest accuracy for complex documents using cloud API")
    print("All: Use same collaborative CrewAI agent framework")

    # Cleanup
    Path(temp_path).unlink()
    Path(form_path).unlink()
    if Path(output_traditional).exists():
        Path(output_traditional).unlink()

    print("\n")


def demo_crewai_error_handling():
    """Demonstrate CrewAI error handling and recovery."""
    print("ü§ñ Demo 5: CrewAI Error Handling")
    print("-" * 50)

    # Test 1: Non-existent file
    print("üß™ Test 1: Non-existent source file")
    crew_processor = DocumentProcessingCrew(text_model="llama3.2:3b")
    result = crew_processor.process_document("non_existent.pdf", "some_form.docx", "output.docx")
    print(f"Result: {'‚úÖ Handled' if not result.success else '‚ùå Unexpected success'}")
    print(f"Error: {result.error}")
    print("ü§ñ CrewAI agents gracefully handled the error")

    # Test 2: Invalid configuration
    print("\nüß™ Test 2: Invalid model configuration")
    try:
        DocumentProcessingCrew(text_model="non_existent_model", extraction_method="traditional")
        print("‚úÖ CrewAI validated configuration and provided fallback")
    except Exception as e:
        print(f"‚úÖ CrewAI caught configuration error: {e}")

    # Test 3: Agent failure simulation
    print("\nüß™ Test 3: Agent collaboration under stress")
    print("ü§ñ CrewAI Features:")
    print("   - Automatic retry mechanisms")
    print("   - Task dependency management")
    print("   - Agent failure recovery")
    print("   - Detailed error reporting")
    print("   - Graceful degradation")

    print("\n")


def demo_crewai_configuration():
    """Show CrewAI configuration options."""
    print("ü§ñ Demo 6: CrewAI Configuration Options")
    print("-" * 50)

    # Different configurations
    configs = [
        {
            "name": "Fast Processing",
            "text_model": "llama3.2:3b",
            "extraction_method": "traditional",
            "description": "Optimized for speed with traditional extraction",
        },
        {
            "name": "High Accuracy (Local)",
            "text_model": "llama3.1:8b",
            "extraction_method": "ai",
            "vision_model": "llava:13b",
            "description": "Maximum accuracy with larger local models",
        },
        {
            "name": "Balanced",
            "text_model": "qwen2.5:7b",
            "extraction_method": "traditional",
            "description": "Good balance of speed and quality",
        },
        {
            "name": "Cloud-Powered",
            "text_model": "llama3.2:3b",
            "extraction_method": "openai",
            "openai_model": "gpt-4-vision-preview",
            "description": "Maximum accuracy using OpenAI's vision API",
        },
    ]

    print("üìã CrewAI Configuration Profiles:")
    for config in configs:
        print(f"\nü§ñ {config['name']}:")
        print(f"   Text Model: {config['text_model']}")
        print(f"   Extraction: {config['extraction_method']}")
        if config.get("vision_model"):
            print(f"   Vision Model: {config['vision_model']}")
        if config.get("openai_model"):
            print(f"   OpenAI Model: {config['openai_model']}")
        print(f"   Use Case: {config['description']}")

    print("\nüîß CrewAI Advanced Settings:")
    print("   - Process Type: Sequential (default) | Hierarchical")
    print("   - Max Retries: 3 per task")
    print("   - Timeout: Configurable per agent")
    print("   - Verbose Mode: Detailed agent logging")
    print("   - Memory: Shared context between agents")

    print("\n‚öôÔ∏è Agent-Specific Configuration:")
    print("   DocumentCollector: Extraction method, vision model")
    print("   Translator: Text model, temperature, max tokens")
    print("   FormAnalyst: Analysis depth, field detection")
    print("   FormFiller: Mapping confidence, field validation")

    print("\n")


def main():
    """Run all CrewAI demos."""
    print("üöÄ Vietnamese Document Form Filler - CrewAI Demo")
    print("=" * 60)
    print("This demo showcases the CrewAI-powered multi-agent")
    print("document processing system.\n")

    # Check if CrewAI and Ollama are available
    print("üîç Checking CrewAI system requirements...")
    try:
        import crewai

        print(f"‚úÖ CrewAI installed: v{crewai.__version__}")

        # Check if crewai_tools is available
        try:
            import crewai_tools  # noqa

            print("‚úÖ CrewAI Tools available")
        except ImportError:
            print("‚ö†Ô∏è CrewAI Tools not available")

        # Check Ollama
        import aiohttp

        async def check_ollama():
            try:
                async with aiohttp.ClientSession() as session, session.get(
                    "http://localhost:11434/api/tags"
                ) as response:
                    if response.status == 200:
                        print("‚úÖ Ollama is running")
                        data = await response.json()
                        models = [m["name"] for m in data.get("models", [])]
                        print(f"Available models: {', '.join(models[:3])}...")
                        return True
                    else:
                        print("‚ùå Ollama is not responding")
                        return False
            except Exception as e:
                print(f"‚ùå Cannot connect to Ollama: {e}")
                return False

        asyncio.run(check_ollama())

    except ImportError as e:
        print(f"‚ùå CrewAI not properly installed: {e}")
        print("Install with: pip install crewai crewai-tools langchain langchain-community")
        return
    except Exception as e:
        print(f"‚ùå System check failed: {e}")
        print("This demo requires CrewAI and Ollama to be running")
        return

    print("\n")

    # Run CrewAI demos
    demo_crewai_single_document()
    demo_crewai_agent_capabilities()
    demo_crewai_batch_processing()
    demo_crewai_extraction_methods()
    demo_crewai_error_handling()
    demo_crewai_configuration()

    print("üéâ CrewAI Demo completed!")
    print("\nü§ñ CrewAI Advantages Summary:")
    print("   ‚úÖ Structured agent collaboration")
    print("   ‚úÖ Built-in error handling and retries")
    print("   ‚úÖ Task dependency management")
    print("   ‚úÖ Enhanced observability and logging")
    print("   ‚úÖ Scalable parallel processing")
    print("   ‚úÖ Easy configuration and customization")
    print("   ‚úÖ Multiple extraction methods (Traditional, AI, OpenAI)")
    print("\nTry the CLI commands or web interface for full CrewAI features!")


if __name__ == "__main__":
    main()  #!/usr/bin/env python3
"""
Demo script for Vietnamese Document Form Filler
Shows basic usage and capabilities
"""


# Demo data - sample Vietnamese text
SAMPLE_VIETNAMESE_TEXT = """
H·ªç v√† t√™n: Nguy·ªÖn VƒÉn An
Ng√†y sinh: 15/03/1990
ƒê·ªãa ch·ªâ: 123 Ph·ªë Hu·∫ø, Qu·∫≠n Hai B√† Tr∆∞ng, H√† N·ªôi
S·ªë ƒëi·ªán tho·∫°i: 0123456789
Email: nguyen.van.an@email.com
Tr√¨nh ƒë·ªô h·ªçc v·∫•n: C·ª≠ nh√¢n C√¥ng ngh·ªá Th√¥ng tin

Kinh nghi·ªám l√†m vi·ªác:
- 2015-2018: L·∫≠p tr√¨nh vi√™n t·∫°i C√¥ng ty ABC
- 2018-2022: Tr∆∞·ªüng nh√≥m ph√°t tri·ªÉn t·∫°i C√¥ng ty XYZ
- 2022-hi·ªán t·∫°i: Ki·∫øn tr√∫c s∆∞ ph·∫ßn m·ªÅm t·∫°i C√¥ng ty DEF

K·ªπ nƒÉng:
- Ng√¥n ng·ªØ l·∫≠p tr√¨nh: Python, Java, JavaScript
- Framework: Django, React, Spring Boot
- C∆° s·ªü d·ªØ li·ªáu: MySQL, PostgreSQL, MongoDB
- DevOps: Docker, Kubernetes, AWS
"""

SAMPLE_FORM_CONTENT = """
EMPLOYMENT APPLICATION FORM

Personal Information:
Name: ___________________
Date of Birth: ___________________
Address: ___________________________________
Phone Number: ___________________
Email: ___________________

Education:
Highest Degree: ___________________
Institution: ___________________

Work Experience:
Previous Position: ___________________
Company: ___________________
Years of Experience: ___________________

Skills:
Technical Skills: ___________________________________
Programming Languages: ___________________
Frameworks: ___________________
Databases: ___________________

Additional Information:
___________________________________________
___________________________________________
"""


async def demo_single_document():
    """Demonstrate single document processing."""
    print("üîπ Demo 1: Single Document Processing")
    print("-" * 40)

    # Create temporary files
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as source_file:
        source_file.write(SAMPLE_VIETNAMESE_TEXT)
        source_path = source_file.name

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as form_file:
        form_file.write(SAMPLE_FORM_CONTENT)
        form_path = form_file.name

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as output_file:
        output_path = output_file.name

    # Initialize processor
    processor = DocumentProcessor(ollama_model="llama3.2:3b")

    print("üìÑ Processing Vietnamese CV...")
    print(f"Source: {Path(source_path).name}")
    print(f"Form: {Path(form_path).name}")

    # Process document
    result = await processor.process_document(source_path, form_path, output_path)

    if result.success:
        print("‚úÖ Success!")
        print(f"Output saved to: {output_path}")

        # Show a preview of the result
        if Path(output_path).exists():
            with open(output_path) as f:
                content = f.read()
                print("\nüìã Preview of filled form:")
                print(content[:300] + "..." if len(content) > 300 else content)
    else:
        print(f"‚ùå Failed: {result.error}")

    # Cleanup
    Path(source_path).unlink()
    Path(form_path).unlink()
    if Path(output_path).exists():
        Path(output_path).unlink()

    print("\n")


async def demo_agent_pipeline():
    """Demonstrate individual agent usage."""
    print("üîπ Demo 2: Individual Agent Pipeline")
    print("-" * 40)

    from document_processor import DocumentCollectorAgent, FormFillerAgent, TranslatorAgent

    # Create agents
    collector = DocumentCollectorAgent()
    translator = TranslatorAgent()
    filler = FormFillerAgent()

    # Create temp files
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as temp_file:
        temp_file.write(SAMPLE_VIETNAMESE_TEXT)
        temp_path = temp_file.name

    print("üîß Step 1: Document Collection")
    collection_result = await collector.process(temp_path)
    if collection_result.success:
        print(f"‚úÖ Extracted {len(collection_result.data)} characters")
        vietnamese_text = collection_result.data[:100] + "..."
        print(f"üìù Sample: {vietnamese_text}")
    else:
        print(f"‚ùå Failed: {collection_result.error}")
        return

    print("\nüîß Step 2: Translation")
    translation_result = await translator.process(collection_result.data)
    if translation_result.success:
        print("‚úÖ Translation completed")
        english_text = translation_result.data[:100] + "..."
        print(f"üìù Sample: {english_text}")
    else:
        print(f"‚ùå Failed: {translation_result.error}")
        return

    print("\nüîß Step 3: Form Filling")
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as form_file:
        form_file.write(SAMPLE_FORM_CONTENT)
        form_path = form_file.name

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as output_file:
        output_path = output_file.name

    filling_result = await filler.process(
        {
            "form_path": form_path,
            "translated_text": translation_result.data,
            "output_path": output_path,
        }
    )

    if filling_result.success:
        print("‚úÖ Form filling completed")
        print(f"üìä Fields filled: {filling_result.metadata.get('filled_count', 'N/A')}")
    else:
        print(f"‚ùå Failed: {filling_result.error}")

    # Cleanup
    Path(temp_path).unlink()
    Path(form_path).unlink()
    if Path(output_path).exists():
        Path(output_path).unlink()

    print("\n")


async def demo_batch_processing():
    """Demonstrate batch processing."""
    print("üîπ Demo 3: Batch Processing")
    print("-" * 40)

    # Create sample documents
    sample_documents = [
        f"Document {i}: T√™n: Ng∆∞·ªùi {i}, Tu·ªïi: {20+i}, ƒê·ªãa ch·ªâ: H√† N·ªôi" for i in range(1, 4)
    ]

    # Create temporary directory structure
    temp_dir = Path(tempfile.mkdtemp())
    input_dir = temp_dir / "input"
    output_dir = temp_dir / "output"
    input_dir.mkdir()
    output_dir.mkdir()

    # Create sample files
    form_path = temp_dir / "form.txt"
    with open(form_path, "w") as f:
        f.write(SAMPLE_FORM_CONTENT)

    # Create input documents
    for i, content in enumerate(sample_documents, 1):
        doc_path = input_dir / f"document_{i}.txt"
        with open(doc_path, "w") as f:
            f.write(content)

    print(f"üìÅ Created {len(sample_documents)} sample documents")
    print(f"Input directory: {input_dir}")
    print(f"Output directory: {output_dir}")

    # Initialize batch processor
    batch_processor = BatchProcessor(model="llama3.2:3b", max_concurrent=2, timeout=60)

    # Discover jobs
    job_count = batch_processor.discover_jobs(
        str(input_dir), str(form_path), str(output_dir), "*.txt"
    )

    print(f"üîç Discovered {job_count} processing jobs")

    # Progress callback
    def progress_callback(completed, total, job):
        progress = (completed / total) * 100
        status = "‚úÖ" if job.status == "completed" else "‚ùå"
        print(f"Progress: {completed}/{total} ({progress:.1f}%) - {status} {job.source_path.name}")

    # Process batch
    print("\nüîÑ Starting batch processing...")
    stats = await batch_processor.process_all(progress_callback)

    print("\nüìä Batch Processing Results:")
    print(f"Total: {stats['total']}")
    print(f"Completed: {stats['completed']}")
    print(f"Failed: {stats['failed']}")
    print(f"Success Rate: {stats['success_rate']:.1f}%")
    print(f"Total Time: {stats['total_time']:.2f}s")
    print(f"Average per Job: {stats['average_job_time']:.2f}s")

    # Cleanup
    import shutil

    shutil.rmtree(temp_dir)

    print("\n")


async def demo_error_handling():
    """Demonstrate error handling scenarios."""
    print("üîπ Demo 4: Error Handling")
    print("-" * 40)

    processor = DocumentProcessor(ollama_model="llama3.2:3b")

    # Test 1: Non-existent file
    print("üß™ Test 1: Non-existent source file")
    result = await processor.process_document("non_existent.pdf", "some_form.docx", "output.docx")
    print(f"Result: {'‚úÖ Handled' if not result.success else '‚ùå Unexpected success'}")
    print(f"Error: {result.error}")

    # Test 2: Empty content
    print("\nüß™ Test 2: Empty document")
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as empty_file:
        empty_file.write("")
        empty_path = empty_file.name

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as form_file:
        form_file.write(SAMPLE_FORM_CONTENT)
        form_path = form_file.name

    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as output_file:
        output_path = output_file.name

    result = await processor.process_document(empty_path, form_path, output_path)
    print(f"Result: {'‚úÖ Handled' if not result.success else '‚ùå Unexpected success'}")
    print(f"Error: {result.error}")

    # Cleanup
    Path(empty_path).unlink()
    Path(form_path).unlink()

    print("\n")


def demo_configuration():
    """Show configuration options."""
    print("üîπ Demo 5: Configuration Options")
    print("-" * 40)

    # Sample configuration
    config = {
        "default_model": "llama3.2:3b",
        "ollama_host": "localhost",
        "ollama_port": 11434,
        "ocr_language": "vie",
        "translation_settings": {
            "temperature": 0.1,
            "max_tokens": 2048,
            "system_prompt": "You are a professional translator...",
        },
        "form_filling_settings": {"confidence_threshold": 0.7, "max_field_mappings": 20},
    }

    print("üìã Sample Configuration:")
    print(json.dumps(config, indent=2))

    print("\nüîß Environment Variables:")
    env_vars = [
        "OLLAMA_HOST=localhost",
        "OLLAMA_PORT=11434",
        "OLLAMA_MODEL=llama3.2:3b",
        "LOG_LEVEL=INFO",
    ]
    for var in env_vars:
        print(f"  export {var}")

    print("\n")


async def main():
    """Run all demos."""
    print("üöÄ Vietnamese Document Form Filler - Demo")
    print("=" * 50)
    print("This demo showcases the capabilities of the multi-agent")
    print("document processing system.\n")

    # Check if Ollama is available
    print("üîç Checking system requirements...")
    try:
        import aiohttp

        async with aiohttp.ClientSession() as session, session.get(
            "http://localhost:11434/api/tags"
        ) as response:
            if response.status == 200:
                print("‚úÖ Ollama is running")
                data = await response.json()
                models = [m["name"] for m in data.get("models", [])]
                print(f"Available models: {', '.join(models[:3])}...")
            else:
                print("‚ùå Ollama is not responding")
                print("Please ensure Ollama is installed and running")
                return
    except Exception as e:
        print(f"‚ùå Cannot connect to Ollama: {e}")
        print("This demo requires Ollama to be running")
        return

    print("\n")

    # Run demos
    await demo_single_document()
    await demo_agent_pipeline()
    await demo_batch_processing()
    await demo_error_handling()
    demo_configuration()

    print("üéâ Demo completed!")
    print("Try the CLI commands or web interface for more features.")


if __name__ == "__main__":
    asyncio.run(main())
